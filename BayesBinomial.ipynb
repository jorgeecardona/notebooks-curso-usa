{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import top_n_list, random_words\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somehow similar languages.\n",
    "LANGUAGES = {\n",
    "    'es': 'Spanish',\n",
    "    'en': 'English',\n",
    "    'pt': 'Portuguese',\n",
    "    'fr': 'French',\n",
    "    'de': 'German',\n",
    "    'it': 'Italian',\n",
    "    'nl': 'Dutch'\n",
    "}\n",
    "\n",
    "LANG_CODES = list(LANGUAGES.keys())\n",
    "\n",
    "# Population of native speakers in Millions.\n",
    "POPULATION = {\n",
    "    'es': 480,\n",
    "    'en': 379,\n",
    "    'pt': 221,\n",
    "    'fr': 77.2,\n",
    "    'de': 76.1,\n",
    "    'it': 64.8,\n",
    "    'nl': 23.1\n",
    "}\n",
    "\n",
    "#[POPULATION.set(lang, 100) for lang in POPULATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de documentos.\n",
    "M = 10000\n",
    "\n",
    "# Numero de clases.\n",
    "n = len(POPULATION)\n",
    "\n",
    "# Generate some random documents.\n",
    "docs = []\n",
    "\n",
    "# Collect the unique words.\n",
    "unique_words = set()\n",
    "\n",
    "# Crear documentos proporcionales a la poblacion.\n",
    "for k in random.choices(list(range(len(POPULATION))), weights=list(POPULATION.values()), k=M):\n",
    "\n",
    "    # Seleccionar 100 palabras al azar.\n",
    "    doc = random_words(lang=LANG_CODES[k], wordlist='best', nwords=10, bits_per_word=8)\n",
    "    docs.append((k, doc))\n",
    "\n",
    "    # Collect unique words.\n",
    "    unique_words = unique_words.union(doc.split())\n",
    "\n",
    "# Numero de palabras.\n",
    "N = len(unique_words)\n",
    "\n",
    "# Parametros.\n",
    "M_k = np.zeros(n)\n",
    "M_jk = np.zeros((N, n))\n",
    "    \n",
    "# Turn uniue words into a list.\n",
    "unique_words = list(unique_words)    \n",
    "\n",
    "# Crear documentos proporcionales a la poblacion.\n",
    "for k, doc in docs:\n",
    "        \n",
    "    # Mas documentos en una clase.\n",
    "    M_k[k] += 1\n",
    "    \n",
    "    for word in set(doc.split()):\n",
    "        M_jk[unique_words.index(word), k] += 1\n",
    "\n",
    " \n",
    "# Fix for zero. Add all the words to all the languages.\n",
    "M += N * n\n",
    "M_k += N\n",
    "M_jk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_b(doc):\n",
    "    \n",
    "    doc = doc.split()\n",
    "    d = np.zeros(N)\n",
    "    \n",
    "    for i, word in enumerate(unique_words):\n",
    "        if word in doc:\n",
    "            d[i] = 1\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(doc):\n",
    "    \n",
    "    # Remove some symbols.\n",
    "    for s in ',.?!':\n",
    "        doc = doc.replace(s, '')\n",
    "\n",
    "    # Representacion binomial.\n",
    "    d = phi_b(doc)    \n",
    "\n",
    "    # Magic.\n",
    "    r = np.sum(np.log(np.einsum('j,jk->jk', d, M_jk) + np.einsum('j,k->jk', 1 - d, M_k) - np.einsum('j,jk->jk', 1 - d, M_jk)), 0) - (N - 1) * np.log(M_k)\n",
    "    \n",
    "    k = r.argmax()\n",
    "    \n",
    "    return LANG_CODES[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(es) \"Hola, mi nombre es Jorge\"\n",
      "(en) \"where is my bag? da\"\n",
      "(de) \"Ich hatte gerne ein cerveza\"\n",
      "(fr) \"je ne sais quoi hola\"\n",
      "(pt) \"eu no falo, bier\"\n",
      "(it) \"io non parlo italiano, what\"\n",
      "(nl) \"Ik spreek geen nederlands, si\"\n"
     ]
    }
   ],
   "source": [
    "DOCS = [\n",
    "    \"Hola, mi nombre es Jorge\",\n",
    "    \"where is my bag? da\",\n",
    "    \"Ich hatte gerne ein cerveza\",\n",
    "    \"je ne sais quoi hola\",\n",
    "    \"eu no falo, bier\",\n",
    "    \"io non parlo italiano, what\",\n",
    "    \"Ik spreek geen nederlands, si\"\n",
    "]\n",
    "\n",
    "for doc in DOCS:\n",
    "    lang = classify(doc)\n",
    "    print(f'({lang}) \"{doc}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
