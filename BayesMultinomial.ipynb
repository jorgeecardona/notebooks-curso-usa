{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import top_n_list, random_words\n",
    "import numba\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somehow similar languages.\n",
    "LANGUAGES = {\n",
    "    'es': 'Spanish',\n",
    "    'en': 'English',\n",
    "    'pt': 'Portuguese',\n",
    "    'fr': 'French',\n",
    "    'de': 'German',\n",
    "    'it': 'Italian',\n",
    "    'nl': 'Dutch'\n",
    "}\n",
    "\n",
    "LANG_CODES = list(LANGUAGES.keys())\n",
    "\n",
    "# Population of native speakers in Millions.\n",
    "POPULATION = {\n",
    "    'es': 480,\n",
    "    'en': 379,\n",
    "    'pt': 221,\n",
    "    'fr': 77.2,\n",
    "    'de': 76.1,\n",
    "    'it': 64.8,\n",
    "    'nl': 23.1\n",
    "}\n",
    "\n",
    "[POPULATION.__setitem__(lang, 100) for lang in POPULATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de documentos.\n",
    "M = 100\n",
    "\n",
    "# Numero de clases.\n",
    "n = len(POPULATION)\n",
    "\n",
    "# Generate some random documents.\n",
    "docs = []\n",
    "\n",
    "# Collect the unique words.\n",
    "unique_words = set()\n",
    "\n",
    "# Keep a count\n",
    "counters = [Counter() for _ in LANG_CODES]\n",
    "\n",
    "# Crear documentos proporcionales a la poblacion.\n",
    "for k in random.choices(list(range(len(POPULATION))), weights=list(POPULATION.values()), k=M):\n",
    "\n",
    "    # Language.\n",
    "    lang = LANG_CODES[k]\n",
    "    \n",
    "    # Document.\n",
    "    doc = random_words(lang=lang, wordlist='best', nwords=50000, bits_per_word=14).split()\n",
    "    \n",
    "    # Count\n",
    "    counters[k].update(doc)\n",
    "\n",
    "# Collect the unique words\n",
    "unique_words = set()\n",
    "\n",
    "for counter in counters:\n",
    "    unique_words = unique_words.union(counter)\n",
    "\n",
    "unique_words = list(unique_words)\n",
    "\n",
    "# Numero de palabras.\n",
    "N = len(unique_words)\n",
    "\n",
    "# Numero total de palabras.\n",
    "M_k = np.array([sum(counter.values()) for counter in counters])\n",
    "M_w = sum(M_k)\n",
    "M_jk = np.array([[counter[w] for counter in counters] for w in unique_words])\n",
    "\n",
    "# Fix for zero. Add all the words to all the languages.\n",
    "M += n\n",
    "M_w += N * n\n",
    "M_k += N\n",
    "M_jk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(doc):\n",
    "    \n",
    "    # Remove some symbols.\n",
    "    for s in ',.?!':\n",
    "        doc = doc.replace(s, '')\n",
    "    \n",
    "    # Eliminar las palabras que no estan en el diccionario.\n",
    "    doc = [w for w in doc.lower().split() if w in unique_words]\n",
    "    \n",
    "    #print(doc)\n",
    "    \n",
    "    assert len(doc) > 0\n",
    "    \n",
    "    r = - (len(doc) - 1) * np.log(M_k)\n",
    "    \n",
    "    for word in doc:\n",
    "        r += np.log(M_jk[unique_words.index(word)])\n",
    "                \n",
    "    k = r.argmax()\n",
    "    \n",
    "    return LANG_CODES[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(es) \"Hola, mi nombre es Jorge, hi\"\n",
      "(de) \"where is my bag? da\"\n",
      "(de) \"Ich hatte gerne ein cerveza,\"\n",
      "(fr) \"je ne sais quoi hola,\"\n",
      "(pt) \"eu não falo, bier, \"\n",
      "(it) \"io non parlo italiano, what\"\n",
      "(nl) \"Ik spreek geen nederlands, muchas gracias\"\n"
     ]
    }
   ],
   "source": [
    "DOCS = [\n",
    "    \"Hola, mi nombre es Jorge, hi\",\n",
    "    \"where is my bag? da\",\n",
    "    \"Ich hatte gerne ein cerveza,\",\n",
    "    \"je ne sais quoi hola,\",\n",
    "    \"eu não falo, bier, \",\n",
    "    \"io non parlo italiano, what\",\n",
    "    \"Ik spreek geen nederlands, muchas gracias\"\n",
    "]\n",
    "\n",
    "for doc in DOCS:\n",
    "    lang = classify(doc)\n",
    "    print(f'({lang}) \"{doc}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
